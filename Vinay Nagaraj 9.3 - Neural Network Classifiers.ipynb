{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Neural Network Classifier with Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(r'categorized-comments.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118579</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I still try and use my vooper in PvP, and you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263253</th>\n",
       "      <td>sports</td>\n",
       "      <td>Bit concerned about hunter because his shootin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298731</th>\n",
       "      <td>video_games</td>\n",
       "      <td>PS4 and X1 version is planned. Not released ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77610</th>\n",
       "      <td>video_games</td>\n",
       "      <td>just bring metacutioner, electro wiz, and torn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461776</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I gotcha. Well that's what's great about the S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381484</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Car charger and LoZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>Still doing the size=specs crap unfortunately.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207025</th>\n",
       "      <td>video_games</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175714</th>\n",
       "      <td>video_games</td>\n",
       "      <td>That's why I stop buying bp :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516948</th>\n",
       "      <td>video_games</td>\n",
       "      <td>People know about your contribution only after...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           cat  \\\n",
       "118579             video_games   \n",
       "263253                  sports   \n",
       "298731             video_games   \n",
       "77610              video_games   \n",
       "461776             video_games   \n",
       "...                        ...   \n",
       "381484             video_games   \n",
       "4931    science_and_technology   \n",
       "207025             video_games   \n",
       "175714             video_games   \n",
       "516948             video_games   \n",
       "\n",
       "                                                      txt  \n",
       "118579  I still try and use my vooper in PvP, and you ...  \n",
       "263253  Bit concerned about hunter because his shootin...  \n",
       "298731  PS4 and X1 version is planned. Not released ye...  \n",
       "77610   just bring metacutioner, electro wiz, and torn...  \n",
       "461776  I gotcha. Well that's what's great about the S...  \n",
       "...                                                   ...  \n",
       "381484                                Car charger and LoZ  \n",
       "4931      Still doing the size=specs crap unfortunately.   \n",
       "207025                                          [deleted]  \n",
       "175714                    That's why I stop buying bp :)   \n",
       "516948  People know about your contribution only after...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = data.sample(n=10000)\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining class column\n",
    "my_encoder = LabelEncoder()\n",
    "my_class_cat = np.array(my_encoder.fit_transform(data_sample['cat'])).reshape(-1,1)\n",
    "#Create a \"diccionary\" to translate the categories into the actual values once you have the output\n",
    "my_class_decoder = list(np.unique(data_sample['cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>cat1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118579</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I still try and use my vooper in PvP, and you ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263253</th>\n",
       "      <td>sports</td>\n",
       "      <td>Bit concerned about hunter because his shootin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298731</th>\n",
       "      <td>video_games</td>\n",
       "      <td>PS4 and X1 version is planned. Not released ye...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77610</th>\n",
       "      <td>video_games</td>\n",
       "      <td>just bring metacutioner, electro wiz, and torn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461776</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I gotcha. Well that's what's great about the S...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381484</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Car charger and LoZ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>Still doing the size=specs crap unfortunately.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207025</th>\n",
       "      <td>video_games</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175714</th>\n",
       "      <td>video_games</td>\n",
       "      <td>That's why I stop buying bp :)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516948</th>\n",
       "      <td>video_games</td>\n",
       "      <td>People know about your contribution only after...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           cat  \\\n",
       "118579             video_games   \n",
       "263253                  sports   \n",
       "298731             video_games   \n",
       "77610              video_games   \n",
       "461776             video_games   \n",
       "...                        ...   \n",
       "381484             video_games   \n",
       "4931    science_and_technology   \n",
       "207025             video_games   \n",
       "175714             video_games   \n",
       "516948             video_games   \n",
       "\n",
       "                                                      txt  cat1  \n",
       "118579  I still try and use my vooper in PvP, and you ...     2  \n",
       "263253  Bit concerned about hunter because his shootin...     1  \n",
       "298731  PS4 and X1 version is planned. Not released ye...     2  \n",
       "77610   just bring metacutioner, electro wiz, and torn...     2  \n",
       "461776  I gotcha. Well that's what's great about the S...     2  \n",
       "...                                                   ...   ...  \n",
       "381484                                Car charger and LoZ     2  \n",
       "4931      Still doing the size=specs crap unfortunately.      0  \n",
       "207025                                          [deleted]     2  \n",
       "175714                    That's why I stop buying bp :)      2  \n",
       "516948  People know about your contribution only after...     2  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample['cat1'] = my_encoder.fit_transform(data_sample['cat'])\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science_and_technology', 'sports', 'video_games']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the features and target\n",
    "X_text_train=data_sample['txt'].values\n",
    "X_text_test=data_sample['txt'].values\n",
    "y=data_sample['cat1'].values\n",
    "num_labels = len(np.unique(data_sample['cat1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the text in training and testing\n",
    "processed_train = []\n",
    "for doc in X_text_train:\n",
    "    tokens = word_tokenize(doc)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    stemmed = [stemmer.stem(word) for word in filtered]\n",
    "    processed_train.append(stemmed)\n",
    "    \n",
    "processed_test = []\n",
    "for doc in X_text_test:\n",
    "    tokens = word_tokenize(doc)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    stemmed = [stemmer.stem(word) for word in filtered]\n",
    "    processed_test.append(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>processed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118579</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I still try and use my vooper in PvP, and you ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, still, tri, use, vooper, pvp, still, ``, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263253</th>\n",
       "      <td>sports</td>\n",
       "      <td>Bit concerned about hunter because his shootin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bit, concern, hunter, shoot, stat, alreadi, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298731</th>\n",
       "      <td>video_games</td>\n",
       "      <td>PS4 and X1 version is planned. Not released ye...</td>\n",
       "      <td>2</td>\n",
       "      <td>[ps4, x1, version, plan, not, releas, yet, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77610</th>\n",
       "      <td>video_games</td>\n",
       "      <td>just bring metacutioner, electro wiz, and torn...</td>\n",
       "      <td>2</td>\n",
       "      <td>[bring, metacution, electro, wiz, tornado, pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461776</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I gotcha. Well that's what's great about the S...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, gotcha, well, 's, 's, great, switch, it, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                                txt  cat1  \\\n",
       "118579  video_games  I still try and use my vooper in PvP, and you ...     2   \n",
       "263253       sports  Bit concerned about hunter because his shootin...     1   \n",
       "298731  video_games  PS4 and X1 version is planned. Not released ye...     2   \n",
       "77610   video_games  just bring metacutioner, electro wiz, and torn...     2   \n",
       "461776  video_games  I gotcha. Well that's what's great about the S...     2   \n",
       "\n",
       "                                            processed_txt  \n",
       "118579  [i, still, tri, use, vooper, pvp, still, ``, k...  \n",
       "263253  [bit, concern, hunter, shoot, stat, alreadi, i...  \n",
       "298731  [ps4, x1, version, plan, not, releas, yet, the...  \n",
       "77610   [bring, metacution, electro, wiz, tornado, pos...  \n",
       "461776  [i, gotcha, well, 's, 's, great, switch, it, c...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample['processed_txt']=processed_train\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_lst = []\n",
    "for lst in data_sample.loc[:,'processed_txt']:\n",
    "    text = ''\n",
    "    for word in lst:\n",
    "        text = text + ' ' + word\n",
    "    row_lst.append(text)\n",
    "\n",
    "data_sample['final_processed_text'] = row_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>cat1</th>\n",
       "      <th>processed_txt</th>\n",
       "      <th>final_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118579</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I still try and use my vooper in PvP, and you ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, still, tri, use, vooper, pvp, still, ``, k...</td>\n",
       "      <td>i still tri use vooper pvp still `` kinda '' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263253</th>\n",
       "      <td>sports</td>\n",
       "      <td>Bit concerned about hunter because his shootin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bit, concern, hunter, shoot, stat, alreadi, i...</td>\n",
       "      <td>bit concern hunter shoot stat alreadi insan h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298731</th>\n",
       "      <td>video_games</td>\n",
       "      <td>PS4 and X1 version is planned. Not released ye...</td>\n",
       "      <td>2</td>\n",
       "      <td>[ps4, x1, version, plan, not, releas, yet, the...</td>\n",
       "      <td>ps4 x1 version plan not releas yet the pc ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77610</th>\n",
       "      <td>video_games</td>\n",
       "      <td>just bring metacutioner, electro wiz, and torn...</td>\n",
       "      <td>2</td>\n",
       "      <td>[bring, metacution, electro, wiz, tornado, pos...</td>\n",
       "      <td>bring metacution electro wiz tornado possibl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461776</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I gotcha. Well that's what's great about the S...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, gotcha, well, 's, 's, great, switch, it, c...</td>\n",
       "      <td>i gotcha well 's 's great switch it cater use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381484</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Car charger and LoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>[car, charger, loz]</td>\n",
       "      <td>car charger loz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>Still doing the size=specs crap unfortunately.</td>\n",
       "      <td>0</td>\n",
       "      <td>[still, size=spec, crap, unfortun]</td>\n",
       "      <td>still size=spec crap unfortun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207025</th>\n",
       "      <td>video_games</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2</td>\n",
       "      <td>[delet]</td>\n",
       "      <td>delet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175714</th>\n",
       "      <td>video_games</td>\n",
       "      <td>That's why I stop buying bp :)</td>\n",
       "      <td>2</td>\n",
       "      <td>[that, 's, i, stop, buy, bp]</td>\n",
       "      <td>that 's i stop buy bp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516948</th>\n",
       "      <td>video_games</td>\n",
       "      <td>People know about your contribution only after...</td>\n",
       "      <td>2</td>\n",
       "      <td>[peopl, know, contribut, game, vote, card, oth...</td>\n",
       "      <td>peopl know contribut game vote card otherwis ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           cat  \\\n",
       "118579             video_games   \n",
       "263253                  sports   \n",
       "298731             video_games   \n",
       "77610              video_games   \n",
       "461776             video_games   \n",
       "...                        ...   \n",
       "381484             video_games   \n",
       "4931    science_and_technology   \n",
       "207025             video_games   \n",
       "175714             video_games   \n",
       "516948             video_games   \n",
       "\n",
       "                                                      txt  cat1  \\\n",
       "118579  I still try and use my vooper in PvP, and you ...     2   \n",
       "263253  Bit concerned about hunter because his shootin...     1   \n",
       "298731  PS4 and X1 version is planned. Not released ye...     2   \n",
       "77610   just bring metacutioner, electro wiz, and torn...     2   \n",
       "461776  I gotcha. Well that's what's great about the S...     2   \n",
       "...                                                   ...   ...   \n",
       "381484                                Car charger and LoZ     2   \n",
       "4931      Still doing the size=specs crap unfortunately.      0   \n",
       "207025                                          [deleted]     2   \n",
       "175714                    That's why I stop buying bp :)      2   \n",
       "516948  People know about your contribution only after...     2   \n",
       "\n",
       "                                            processed_txt  \\\n",
       "118579  [i, still, tri, use, vooper, pvp, still, ``, k...   \n",
       "263253  [bit, concern, hunter, shoot, stat, alreadi, i...   \n",
       "298731  [ps4, x1, version, plan, not, releas, yet, the...   \n",
       "77610   [bring, metacution, electro, wiz, tornado, pos...   \n",
       "461776  [i, gotcha, well, 's, 's, great, switch, it, c...   \n",
       "...                                                   ...   \n",
       "381484                                [car, charger, loz]   \n",
       "4931                   [still, size=spec, crap, unfortun]   \n",
       "207025                                            [delet]   \n",
       "175714                       [that, 's, i, stop, buy, bp]   \n",
       "516948  [peopl, know, contribut, game, vote, card, oth...   \n",
       "\n",
       "                                     final_processed_text  \n",
       "118579   i still tri use vooper pvp still `` kinda '' ...  \n",
       "263253   bit concern hunter shoot stat alreadi insan h...  \n",
       "298731   ps4 x1 version plan not releas yet the pc ver...  \n",
       "77610    bring metacution electro wiz tornado possibl ...  \n",
       "461776   i gotcha well 's 's great switch it cater use...  \n",
       "...                                                   ...  \n",
       "381484                                    car charger loz  \n",
       "4931                        still size=spec crap unfortun  \n",
       "207025                                              delet  \n",
       "175714                              that 's i stop buy bp  \n",
       "516948   peopl know contribut game vote card otherwis ...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_sample['final_processed_text'],\n",
    "                                                   data_sample['cat1'],\n",
    "                                                   test_size=0.33,\n",
    "                                                   random_state=8675309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.31      0.39       143\n",
      "           1       0.53      0.49      0.51       796\n",
      "           2       0.81      0.85      0.83      2361\n",
      "\n",
      "    accuracy                           0.74      3300\n",
      "   macro avg       0.63      0.55      0.58      3300\n",
      "weighted avg       0.73      0.74      0.73      3300\n",
      "\n",
      "\n",
      "[[  44   28   71]\n",
      " [   9  393  394]\n",
      " [  27  325 2009]]\n"
     ]
    }
   ],
   "source": [
    "# fitting a MLP model to the data\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train_cv, y_train)\n",
    "print(); print(model)\n",
    "\n",
    "# making predictions\n",
    "expected_y  = y_test\n",
    "predicted_y = model.predict(X_test_cv)\n",
    "\n",
    "# summarizing the fit of the model\n",
    "print(); print(metrics.classification_report(expected_y, predicted_y))\n",
    "print(); print(metrics.confusion_matrix(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = MLPRegressor(solver='lbfgs', alpha=1e-5, \n",
    "                     hidden_layer_sizes=(50,50), max_iter=500, random_state=1)\n",
    "mlr.fit(X_train_cv, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199775580848606"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = MLPRegressor(solver='lbfgs', alpha=1e-5, \n",
    "                     hidden_layer_sizes=(50,50), max_iter=500, random_state=1)\n",
    "mlr.fit(X_test_cv, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158756414655458"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network Classifier with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_cv.shape[1]\n",
    "N_classes = 3\n",
    "\n",
    "def build_network():\n",
    "    nn=Sequential()\n",
    "    nn.add(Dense(500, activation='relu', input_dim=input_dim))\n",
    "    nn.add(Dense(150, activation='relu'))\n",
    "    nn.add(Dense(N_classes, activation='softmax'))\n",
    "    nn.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('nn', KerasClassifier(build_fn=build_network,\n",
    "                          epochs=1,\n",
    "                          batch_size=1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    X = X_train_cv\n",
    "    y = y_train\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy')\n",
    "    model.fit(X,y)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360/5360 [==============================] - 99s 18ms/step - loss: 0.6651 - accuracy: 0.7488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinaynagaraj/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360/5360 [==============================] - 116s 22ms/step - loss: 0.6766 - accuracy: 0.7329\n",
      "5360/5360 [==============================] - 111s 21ms/step - loss: 0.6642 - accuracy: 0.7351\n",
      "5360/5360 [==============================] - 112s 21ms/step - loss: 0.6558 - accuracy: 0.7479\n",
      "5360/5360 [==============================] - 124s 23ms/step - loss: 0.6677 - accuracy: 0.7398\n",
      "6700/6700 [==============================] - 132s 20ms/step - loss: 0.6673 - accuracy: 0.7458\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Dense\n",
    "scores = train_model(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classifying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color channel value to be first\n",
    "K.set_image_data_format('channels_last')\n",
    "#K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode target \n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add convolutional layer with 64 filters, a 5x5 window and ReLU activation function \n",
    "network.add(Conv2D(filters=64,\n",
    "                  kernel_size=(5, 5),\n",
    "                  input_shape=(height, width, channels),\n",
    "                  activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add max pooling layer with a 2x2 window\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layer to flatten input\n",
    "network.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer of 128 units with a ReLU activation function \n",
    "network.add(Dense(128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\",\n",
    "               optimizer=\"rmsprop\",\n",
    "               metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "nnModel = network.fit(features_train,\n",
    "           target_train,\n",
    "           epochs=2,\n",
    "           verbose=0,\n",
    "           batch_size=1000,\n",
    "           validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(nnModel.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = nnModel.history['loss']\n",
    "val_loss   = nnModel.history['val_loss']\n",
    "train_acc  = nnModel.history['accuracy']\n",
    "val_acc    = nnModel.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8097500205039978, 0.9396833181381226]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training dataset accuracy\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9519000053405762, 0.9704999923706055]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation dataset accuracy\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
